{\rtf1\ansi\ansicpg1252\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Limitations of Random Forest:\
https://towardsdatascience.com/a-limitation-of-random-forest-regression-db8ed7419e9f\
\
Covariate Shift:\
https://www.analyticsvidhya.com/blog/2017/07/covariate-shift-the-hidden-problem-of-real-world-data-science/\
\
NB: Target variable or Prior Probability Shift example:\
 interest rates lower - financing abundant - home prices much higher\
\
Context:\
\
Half above and half below:\
https://www.zdnet.com/article/zillow-machine-learning-and-data-in-real-estate/\
\
Others:\
https://analyticsindiamag.com/zillows-great-data-science-disaster/\
https://towardsdatascience.com/invaluable-data-science-lessons-to-learn-from-the-failure-of-zillows-flipping-business-25fdc218a62\
\
Lecture Plan:\
1. Upload raw data to Azure AutoML for regression task\
2. Manual ETA in R, SLR model, assumptions check, MLR model regsubsets baseline, \
2.2 Assumptions checks, outliers, measures of influence \
3. Split into several files with train/test routine\
4. Create AWS cluster, upload 2 files with same schema, notebook with spark df\
5. Grid search with sklearn or spark ML, create global feature importances chart\
6. Back to Azure AutoML, compare model performance and feature importances\
7. TBD \'97>  compare models on oos for price prediction: 3 homes with 10 bedrooms, 1 home with 11 bedrooms, and 1 with 33. How the rules of neighborhood can hurt your prediction.\
8. Consider quantile regression in Spark}